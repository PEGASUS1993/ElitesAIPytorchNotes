先整理下错题  

假如你正在实现一个全连接层，全连接层的输入形状是7 \times 87×8，输出形状是7 \times 17×1，其中7是批量大小，则权重参数ww和偏置参数bb的形状分别是____和____  
设输入批量为X \in \mathbb{R}^{7 \times 8}X∈R 
7×8
 ，对应的输出为Y \in \mathbb{R}^{7 \times 1}Y∈R 
7×1
 ，令权重参数为w \in \mathbb{R}^{8 \times 1}w∈R 
8×1
 ，则Xw \in \mathbb{R}^{7 \times 1}Xw∈R 
7×1
 ，然后我们给XwXw中的每个元素加上的偏置是一样的，所以偏置参数b \in \mathbb{R} ^{1 \times 1}b∈R 
1×1
 ，基于加法的广播机制，可以完成得到输出Y = Xw + bY=Xw+b。参数的形状与批量大小没有关系，也正是因为如此，对同一个模型，我们可以选择不同的批量大小。
 # 线性回归
主要内容包括：

1. 线性回归的基本要素
2. 线性回归模型从零开始的实现
3. 线性回归模型使用pytorch的简洁实现
